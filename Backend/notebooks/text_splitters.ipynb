{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0294791-33a2-4ac3-b1c2-4e8cef3442e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document loader with success number of pages: 13 pages\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter\n",
    ")\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"test.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"document loader with success number of pages: {len(documents)} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ae52b9-26b5-487f-8102-312e894ea870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 3219\n",
      "Approximate tokens (chars/4): 804.75\n",
      "\n",
      "üí° This is why we need to split documents into chunks\n"
     ]
    }
   ],
   "source": [
    "full_text = \" \".join([doc.page_content for doc in documents])\n",
    "\n",
    "print(f\"Total characters: {len(full_text)}\")\n",
    "print(f\"Approximate tokens (chars/4): {len(full_text) / 4}\")\n",
    "print(\"\\nüí° This is why we need to split documents into chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a67bbac9-c1c6-49ca-9f11-b481bee8ab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è  Split into 13 chunks\n",
      "\n",
      "üì¶ First chunk:\n",
      "Nagle's algorithm\n",
      "Delay in the client side\n",
      "husseinnasser\n",
      "\n",
      "üì¶ Second chunk:\n",
      "Nigel Algorithm\n",
      "‚óè In the telnet days sending a single byte in a segment is a waste\n",
      "‚óè Combine small segments and send them in a single one\n",
      "‚óè The client can wait for a full MSS before sending the segment\n",
      "‚óè No wasted 40 bytes header (IP + TCP) for few bytes of data\n",
      "husseinnasser\n"
     ]
    }
   ],
   "source": [
    "# Create a simple splitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",  \n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "# Split our documents\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"‚úÇÔ∏è  Split into {len(chunks)} chunks\")\n",
    "print(f\"\\nüì¶ First chunk:\")\n",
    "print(chunks[0].page_content)\n",
    "print(f\"\\nüì¶ Second chunk:\")\n",
    "print(chunks[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33397eb1-dee9-4f08-85d0-cfec0d12110e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è  Split into 13 chunks\n",
      "\n",
      "üì¶ Sample chunk:\n",
      "Nagle's algorithm\n",
      "Delay in the client side\n",
      "husseinnasser\n"
     ]
    }
   ],
   "source": [
    "# This is the BEST splitter for most use cases\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # Try these in order\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "recursive_chunks = recursive_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"‚úÇÔ∏è  Split into {len(recursive_chunks)} chunks\")\n",
    "print(f\"\\nüì¶ Sample chunk:\")\n",
    "print(recursive_chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "183d482a-135d-43e3-918b-e079926f67a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original document metadata: {'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': \"Nagle's algorithm\", 'source': 'test.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}\n",
      "Chunk metadata: {'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': \"Nagle's algorithm\", 'source': 'test.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "chunk = recursive_chunks[0]\n",
    "\n",
    "print(\"Original document metadata:\", documents[0].metadata)\n",
    "print(\"Chunk metadata:\", chunk.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb90b23-a80e-45fb-a99c-c5fbfa69ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split documents into chunks using the best splitter\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "    \n",
    "    chunks = splitter.split_documents(documents)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcdf969-a7c6-4cc5-a7c7-c0f316464772",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_documents("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
